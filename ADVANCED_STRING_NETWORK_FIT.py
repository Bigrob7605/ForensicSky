#!/usr/bin/env python3
"""
ADVANCED STRING NETWORK FIT - Bayesian Evidence Comparison
=========================================================

Proper Bayesian model comparison for string network detection
"""

import numpy as np
import json
import sys
from pathlib import Path
import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist, squareform
from scipy.optimize import minimize
from scipy.stats import chi2
import warnings
warnings.filterwarnings('ignore')

def string_wake_template(toas, t_k, A, w=30):
    """String wake template: |t - t_k|^(4/3) with width w"""
    dt = (toas - t_k) / w
    mask = np.abs(dt) < 1
    tmpl = np.zeros_like(toas)
    tmpl[mask] = A * np.abs(dt[mask])**(4/3)
    return tmpl

def angular_separation(ra1, dec1, ra2, dec2):
    """Calculate angular separation between two points on the sky"""
    ra1, dec1, ra2, dec2 = np.radians([ra1, dec1, ra2, dec2])
    cos_sep = np.sin(dec1) * np.sin(dec2) + np.cos(dec1) * np.cos(dec2) * np.cos(ra1 - ra2)
    cos_sep = np.clip(cos_sep, -1, 1)
    return np.degrees(np.arccos(cos_sep))

def log_likelihood_string_network(theta, resids, toas, psr_positions, white_var=1e-12):
    """Log likelihood for string network model with proper priors"""
    # theta = [log_GŒº, t1, t2, t3, ra1, dec1, ra2, dec2, ra3, dec3, log_theta_kern]
    log_GŒº = theta[0]
    GŒº = 10**log_GŒº
    
    # Prior on GŒº (GUT scale: 10^-11 to 10^-10)
    if log_GŒº < -12 or log_GŒº > -9:
        return -np.inf
    
    t_k = theta[1:4]  # 3 string crossing times
    ra_k = theta[4:7]  # 3 string node RA
    dec_k = theta[7:10]  # 3 string node DEC
    log_theta_kern = theta[10]
    theta_kern = 10**log_theta_kern
    
    # Prior on kernel width (5-20 degrees)
    if theta_kern < 5 or theta_kern > 20:
        return -np.inf
    
    # Prior on string crossing times (within data range)
    t_min, t_max = min([t.min() for t in toas]), max([t.max() for t in toas])
    if np.any(t_k < t_min) or np.any(t_k > t_max):
        return -np.inf
    
    # String node positions
    pos_k = np.array([ra_k, dec_k]).T  # 3 string nodes
    
    ll = 0
    for i, (r, t, pos_p) in enumerate(zip(resids, toas, psr_positions)):
        # Calculate angular separations from pulsar to all string nodes
        dtheta = np.array([angular_separation(pos_p[0], pos_p[1], ra, dec) for ra, dec in zip(ra_k, dec_k)])
        
        # Kernel weights
        kern = np.exp(-(dtheta / theta_kern)**2)
        
        # String wake model
        model = np.zeros_like(t)
        for tk, k in zip(t_k, kern):
            model += string_wake_template(t, tk, GŒº * k)
        
        # Log likelihood
        ll += -0.5 * np.sum((r - model)**2 / white_var)
    
    return ll

def log_likelihood_null(theta, resids, toas, white_var=1e-12):
    """Log likelihood for null model (independent red noise) with priors"""
    # theta = [log_red_var] for each pulsar
    n_pulsars = len(resids)
    log_red_var = theta[:n_pulsars]
    red_var = 10**log_red_var
    
    # Prior on red noise variance (reasonable range)
    if np.any(red_var < 1e-15) or np.any(red_var > 1e-6):
        return -np.inf
    
    ll = 0
    for i, (r, t) in enumerate(zip(resids, toas)):
        # Simple red noise model
        ll += -0.5 * np.sum(r**2 / (red_var[i] + white_var))
    
    return ll

def fit_string_network_robust(resids, toas, psr_positions):
    """Robust string network fit with multiple initializations"""
    print("\nüîç FITTING STRING NETWORK MODEL (ROBUST)")
    print("-" * 70)
    
    n_pulsars = len(resids)
    best_result = None
    best_ll = -np.inf
    
    # Try multiple initializations
    for attempt in range(5):
        print(f"  Attempt {attempt + 1}/5...")
        
        # Random initialization
        log_GŒº_init = np.random.uniform(-11.5, -10.5)
        t_k_init = np.random.uniform(min([t.min() for t in toas]), max([t.max() for t in toas]), 3)
        ra_k_init = np.random.uniform(0, 360, 3)
        dec_k_init = np.random.uniform(-90, 90, 3)
        log_theta_kern_init = np.random.uniform(0.7, 1.3)  # 5-20 degrees
        
        initial_params = np.concatenate([[log_GŒº_init], t_k_init, ra_k_init, dec_k_init, [log_theta_kern_init]])
        
        def neg_log_likelihood(theta):
            return -log_likelihood_string_network(theta, resids, toas, psr_positions)
        
        result = minimize(neg_log_likelihood, initial_params, method='Nelder-Mead', options={'maxiter': 1000})
        
        if result.success:
            ll = -result.fun
            if ll > best_ll:
                best_ll = ll
                best_result = result
                print(f"    ‚úÖ New best: logL = {ll:.2f}")
            else:
                print(f"    ‚ö†Ô∏è  logL = {ll:.2f} (not best)")
        else:
            print(f"    ‚ùå Failed to converge")
    
    if best_result is not None:
        theta_opt = best_result.x
        log_GŒº = theta_opt[0]
        t_k = theta_opt[1:4]
        ra_k = theta_opt[4:7]
        dec_k = theta_opt[7:10]
        log_theta_kern = theta_opt[10]
        
        GŒº = 10**log_GŒº
        theta_kern = 10**log_theta_kern
        
        print(f"‚úÖ String network fit converged!")
        print(f"GŒº = {GŒº:.2e}")
        print(f"String crossing times: {t_k}")
        print(f"String node positions: RA={ra_k}, DEC={dec_k}")
        print(f"Kernel width: {theta_kern:.1f}¬∞")
        print(f"Log-likelihood: {best_ll:.2f}")
        
        return theta_opt, best_ll
    else:
        print("‚ùå String network fit failed to converge")
        return None, None

def fit_null_model_robust(resids, toas):
    """Robust null model fit"""
    print("\nüîç FITTING NULL MODEL (ROBUST)")
    print("-" * 60)
    
    n_pulsars = len(resids)
    best_result = None
    best_ll = -np.inf
    
    # Try multiple initializations
    for attempt in range(3):
        print(f"  Attempt {attempt + 1}/3...")
        
        # Random initialization
        log_red_var_init = np.random.uniform(-15, -9, n_pulsars)
        
        def neg_log_likelihood(theta):
            return -log_likelihood_null(theta, resids, toas)
        
        result = minimize(neg_log_likelihood, log_red_var_init, method='Nelder-Mead', options={'maxiter': 1000})
        
        if result.success:
            ll = -result.fun
            if ll > best_ll:
                best_ll = ll
                best_result = result
                print(f"    ‚úÖ New best: logL = {ll:.2f}")
            else:
                print(f"    ‚ö†Ô∏è  logL = {ll:.2f} (not best)")
        else:
            print(f"    ‚ùå Failed to converge")
    
    if best_result is not None:
        log_red_var = best_result.x
        red_var = 10**log_red_var
        
        print(f"‚úÖ Null model fit converged!")
        print(f"Red noise variances: {red_var}")
        print(f"Log-likelihood: {best_ll:.2f}")
        
        return best_result.x, best_ll
    else:
        print("‚ùå Null model fit failed to converge")
        return None, None

def create_realistic_synthetic_data():
    """Create more realistic synthetic data"""
    print("üß™ Creating realistic synthetic data...")
    
    # 6 pulsars with known positions (approximate)
    psr_positions = [
        (326.8, -7.8),   # J2145-0750
        (240.0, -30.9),  # J1600-3053
        (251.0, -12.4),  # J1643-1224
        (93.3, -2.0),    # J0613-0200
        (92.5, -21.0),   # J0610-2100
        (270.5, -21.4)   # J1802-2124
    ]
    
    # Generate synthetic timing data
    n_points = 200
    mjd_start = 50000
    mjd_end = 60000
    
    resids = []
    toas = []
    
    # String network parameters
    GŒº = 1e-11  # GUT scale
    t_string = 55000  # String crossing time
    theta_kern = 10   # Kernel width in degrees
    
    for i, (ra, dec) in enumerate(psr_positions):
        # Generate TOAs
        t = np.linspace(mjd_start, mjd_end, n_points)
        
        # Generate residuals with realistic noise
        r = np.random.normal(0, 1e-6, n_points)
        
        # Add string wake signature (only for some pulsars to test detection)
        if i < 3:  # Only first 3 pulsars have string signature
            # Calculate angular separation from string (simplified)
            dtheta = np.random.uniform(5, 15)  # Random separation
            kern = np.exp(-(dtheta / theta_kern)**2)
            
            # Add string wake
            dt = (t - t_string) / 30  # 30 day width
            mask = np.abs(dt) < 1
            r[mask] += GŒº * kern * np.abs(dt[mask])**(4/3)
        
        resids.append(r)
        toas.append(t)
    
    print(f"‚úÖ Generated realistic synthetic data for {len(psr_positions)} pulsars")
    return resids, toas, psr_positions

def main():
    """Run the advanced string network fit analysis"""
    print("üöÄ ADVANCED STRING NETWORK FIT - BAYESIAN EVIDENCE")
    print("=" * 70)
    print("Proper Bayesian model comparison for string network detection")
    print()
    
    # Create realistic synthetic data
    resids, toas, psr_positions = create_realistic_synthetic_data()
    
    print(f"üìä Data summary:")
    print(f"  Pulsars: {len(resids)}")
    print(f"  Data points per pulsar: {len(resids[0])}")
    print(f"  Time range: {toas[0][0]:.0f} - {toas[0][-1]:.0f} MJD")
    
    # Fit null model
    null_params, null_ll = fit_null_model_robust(resids, toas)
    
    # Fit string network model
    string_params, string_ll = fit_string_network_robust(resids, toas, psr_positions)
    
    if null_params is not None and string_params is not None:
        # Compare models
        print(f"\nüéØ BAYESIAN MODEL COMPARISON")
        print("-" * 50)
        
        delta_ll = string_ll - null_ll
        
        print(f"Null model log-likelihood: {null_ll:.2f}")
        print(f"String network log-likelihood: {string_ll:.2f}")
        print(f"Œîlog-likelihood: {delta_ll:.2f}")
        
        # Bayesian evidence thresholds
        if delta_ll > 10:
            print("‚úÖ STRING NETWORK STRONGLY FAVORED! ŒîlogL > 10")
            print("   - Bayes factor > 10^4")
            print("   - Publishable detection!")
        elif delta_ll > 5:
            print("‚ö†Ô∏è  STRING NETWORK MODERATELY FAVORED (ŒîlogL > 5)")
            print("   - Bayes factor > 10^2")
            print("   - Worth further investigation")
        elif delta_ll > 2:
            print("‚ö†Ô∏è  STRING NETWORK WEAKLY FAVORED (ŒîlogL > 2)")
            print("   - Bayes factor > 10")
            print("   - Marginal evidence")
        else:
            print("‚ùå NO STRING NETWORK EVIDENCE (ŒîlogL < 2)")
            print("   - Bayes factor < 10")
            print("   - Null model preferred")
        
        # Save results
        results = {
            'null_model': {
                'params': null_params.tolist(),
                'log_likelihood': float(null_ll)
            },
            'string_network': {
                'params': string_params.tolist(),
                'log_likelihood': float(string_ll)
            },
            'delta_log_likelihood': float(delta_ll),
            'bayes_factor': float(np.exp(delta_ll)),
            'psr_positions': psr_positions,
            'interpretation': {
                'strong_evidence': delta_ll > 10,
                'moderate_evidence': 5 < delta_ll <= 10,
                'weak_evidence': 2 < delta_ll <= 5,
                'no_evidence': delta_ll <= 2
            }
        }
        
        with open('advanced_string_network_results.json', 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\nüìä Results saved to 'advanced_string_network_results.json'")
    
    print(f"\nüéØ ANALYSIS COMPLETE!")
    print("=" * 50)

if __name__ == "__main__":
    main()
